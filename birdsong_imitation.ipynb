{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "1. The subjects are labelled as 0-14, while the species are from 1-10. \n",
    "(Due to a mistake I made while outputing the data into a format for Python...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 import the moduls\n",
    "import scipy.io as sio\n",
    "import librosa as lb\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.decomposition import PCA\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Function for extracting features \n",
    "def getfeatures(fdata):\n",
    "\n",
    "    data = np.array([lb.feature.rmse(y = fdata,frame_length=1024, hop_length=512)])[0,0]\n",
    "    threshold = np.ndarray.max(data[1:10])\n",
    "\n",
    "    length = fdata.size\n",
    "    data_order = data.argsort()[-5:][::-1]\n",
    "    for i in range(0,4):\n",
    "        start = data_order[i] * 512 - 4090\n",
    "        end = data_order[i] * 512 + 4099\n",
    "        if length < end + 1 :\n",
    "            end = length - 1\n",
    "    \n",
    "        fade = fdata[end] / 2\n",
    "        target = np.append(fdata[start : end],[fade])\n",
    "        target = np.append(target,0)\n",
    "    \n",
    "        if max(np.correlate(target,target,'same')) > 10:\n",
    "            break\n",
    "            \n",
    "         \n",
    "    mfccs = lb.feature.mfcc(y=target, sr=44100, n_mfcc=14, n_fft = 8192,hop_length = 8192)    \n",
    "    mfccs = mfccs[1:14]\n",
    "    return mfccs, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Initiate the feature vectors\n",
    "subjects = []\n",
    "species_all = []\n",
    "mfcc_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Get voice imitation in (Need to manually go from test_1 to test_6 for all imitations)\n",
    "test = sio.loadmat('test_1.mat')\n",
    "audio = test['audio_1']\n",
    "num_row = int(np.shape(audio)[0])\n",
    "\n",
    "# 5 And for each audio clip in each .mat, extract the features\n",
    "for i in tqdm(range(num_row)):\n",
    "    temp_sub = audio[i,0]\n",
    "    temp_spe = audio[i,1]\n",
    "    rdata = audio[i,2:-1]\n",
    "    rdata_nz = np.nonzero(rdata)[0][-1]\n",
    "    fdata = rdata[0:rdata_nz]\n",
    "    \n",
    "    mfccs,target = getfeatures(fdata)\n",
    "\n",
    "    subjects.append(temp_sub)\n",
    "    species_all.append(temp_spe)\n",
    "    \n",
    "    #!!!! This part need to be commented out if the code is being not runned on test_1\n",
    "    if i == 0:\n",
    "        mfcc_all = mfccs\n",
    "    else:    \n",
    "    #!!!    \n",
    "        mfcc_all = np.append(mfcc_all,mfccs,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 prepare data for clustering and visualization\n",
    "data = mfcc_all\n",
    "species_all = np.array(species_all)\n",
    "data_flip = list(map(list, zip(*data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 Do clustering(for labels) and PCA(only for visualization)\n",
    "mfcc_pca = PCA(n_components = 2)\n",
    "results = mfcc_pca.fit_transform(data_flip)\n",
    "db = KMeans(n_clusters=2).fit(data_flip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 Visualizing clustering results\n",
    "fig = plt.figure(figsize=(12, 9))\n",
    "plt.scatter(results[:,0], results[:,1],c=db.labels_.astype(np.float), edgecolor='k')\n",
    "    \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 Calculate the numbers of whistled recordings for each species & subject\n",
    "sub = []\n",
    "for i in range(15):\n",
    "    ind_whis = np.where(db.labels_ == 0)[0]\n",
    "    sub.append(sum((subjects[s] == i) for s in ind_whis))\n",
    "sub = np.array(sub)\n",
    "\n",
    "spe = []\n",
    "for j in range(1,11):\n",
    "    spe_whis = np.where(db.labels_ == 0)[0]\n",
    "    spe.append(sum((species_all[t] == j) for t in spe_whis))\n",
    "spe = np.array(spe)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 Plot whistled recording percentage of each species\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "subject_len = len(set(subjects))\n",
    "species1 = plt.bar(range(10),subject_len*10-spe)\n",
    "species2 = plt.bar(range(10),spe,bottom=(subject_len*10-spe))\n",
    "\n",
    "plt.ylabel('numbers of recording')\n",
    "\n",
    "plt.title('whistle as strategy')\n",
    "plt.xlabel('species')\n",
    "plt.xticks(np.arange(10),('Mourning dove','Sora','sparrow','Northern cardinal','Veery','Chikadee','Vireo','Prairie warbler','Yellowthroat','Blue warbler'))\n",
    "plt.tick_params(axis = 'both', labelsize = 8)\n",
    "plt.legend((species1[0], species2[0]), ('Whistle', 'Non-whistle'))\n",
    "plt.ylim(0,(subject_len+2)*10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11 Plot whistle results between subjects\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "sub = sub[sub>0]\n",
    "non_sub = 100-sub\n",
    "subjects1 = plt.bar(range(1,subject_len+1),non_sub)\n",
    "subjects2 = plt.bar(range(1,subject_len+1),sub,bottom=non_sub)\n",
    "\n",
    "plt.ylabel('numbers of recording')\n",
    "plt.xlabel('subjects')\n",
    "plt.title('whistle as strategy')\n",
    "plt.xticks(np.arange(1,subject_len+1))\n",
    "plt.legend((subjects1[0], subjects2[0]), ('Whistle', 'Non-whistle'))\n",
    "plt.ylim(0,120)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-2 Voice Activity Detection function\n",
    "def detect_activity(y, sr,\n",
    "        n_mels=128, fmin=1000, fmax=11025, \n",
    "        hop_length=512, gain=0.8, bias=10, power=0.25, pcen_time_constant=0.06, eps=1e-06,\n",
    "        medfilt_time_constant=None, normalized=True,\n",
    "        peak_threshold=0.45, activity_threshold=0.2):\n",
    "    # 1. Compute mel-frequency spectrogram\n",
    "    melspec = lb.feature.melspectrogram(\n",
    "        y, sr=sr, fmin=fmin, fmax=fmax, hop_length=hop_length,\n",
    "        n_mels=n_mels)\n",
    "    \n",
    "    # 2. Compute per-channel energy normalization (PCEN-SNR)\n",
    "    pcen = lb.core.pcen(melspec, sr=sr, gain=gain, bias=bias,\n",
    "        power=power, hop_length=hop_length,\n",
    "        time_constant=pcen_time_constant, eps=eps)\n",
    "    \n",
    "    # 3. compute PCEN-SNR detection function\n",
    "    pcen_snr = np.max(pcen,axis=0) - np.min(pcen,axis=0)\n",
    "    pcen_snr = lb.power_to_db(pcen_snr / np.median(pcen_snr))\n",
    "    if normalized:\n",
    "        pcen_snr = pcen_snr / np.max(pcen_snr)\n",
    "        \n",
    "    # 4. Apply median filtering.\n",
    "    if medfilt_time_constant is not None:\n",
    "        medfilt_hops = medfilt_time_constant * sr / hop_length\n",
    "        kernel_size = max(1, 1 + 2 * round(medfilt_hops - 0.5))\n",
    "        pcen_snr = scipy.signal.medfilt(pcen_snr, kernel_size=kernel_size)\n",
    "    \n",
    "    # 5. Extract active segments.\n",
    "    activity, start, end = threshold_activity(\n",
    "        pcen_snr, peak_threshold, activity_threshold)\n",
    "    \n",
    "    # 6. Convert indices to seconds.\n",
    "    start_times = np.round(np.array(start) * hop_length / sr, 3)\n",
    "    end_times = np.round(np.array(end) * hop_length / sr, 3)\n",
    "    \n",
    "    return start_times, end_times\n",
    "\n",
    "def threshold_activity(x, Tp, Ta):\n",
    "    locs = signal.find_peaks(x,height = Tp)[0]\n",
    "    y = (x > Ta) * 1\n",
    "    act = np.diff(y)\n",
    "    u = np.where(act == 1)[0]\n",
    "    d = np.where(act == -1)[0]\n",
    "    signal_length = len(x)\n",
    "    \n",
    "    if d[0] < u[0]:\n",
    "        u = np.insert(u, 0, 0)\n",
    "        \n",
    "    if d[-1] < u[-1]:\n",
    "        d = np.append(d, signal_length-1)\n",
    "        \n",
    "    starts = []\n",
    "    ends = []\n",
    "    \n",
    "    activity = np.zeros(signal_length,)\n",
    "    \n",
    "    for candidate_up, candidate_down in zip(u, d):\n",
    "        candidate_segment = range(candidate_up, candidate_down)\n",
    "        peaks_in_segment = [x in candidate_segment for x in locs]\n",
    "        is_valid_candidate = np.any(peaks_in_segment)\n",
    "        if is_valid_candidate:\n",
    "            starts.append(candidate_up)\n",
    "            ends.append(candidate_down)\n",
    "            activity[candidate_segment] = 1.0\n",
    "            \n",
    "    starts = np.array(starts)\n",
    "    ends = np.array(ends)\n",
    "    return activity, starts, ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-3 Get the stimuli in\n",
    "stimuli_set = sio.loadmat('stimuli.mat')\n",
    "stimuli = stimuli_set['audio_sti']\n",
    "\n",
    "# (use the codes from above section to get imitations in again) test_1 to test_6\n",
    "#test = sio.loadmat('test_1.mat')\n",
    "#audio = test['audio_1']\n",
    "#num_row = int(np.shape(audio)[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use detection_activity to get the number of syllables from all stimuli\n",
    "\n",
    "# Since subject's data is distributed in several mat files\n",
    "# we need to keep a count of how many is used eventually\n",
    "total_subject = 0\n",
    "each_number_events = []\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    temp_sub = stimuli[i,0]\n",
    "    temp_spe = stimuli[i,1]\n",
    "    rdata = stimuli[i,2:-1]\n",
    "    rdata_nz = np.nonzero(rdata)[0][-1]\n",
    "    fdata = rdata[0:rdata_nz]\n",
    "    \n",
    "    if np.mean(lb.feature.spectral_flatness(fdata)) > 0.35:\n",
    "        number_events.append(0)\n",
    "    \n",
    "    else:\n",
    "        start, end = detect_activity(fdata,sr)\n",
    "        activity_count = len(start)\n",
    "        each_number_events.append(activity_count)\n",
    "        \n",
    "all_number_events = np.array(each_number_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-4 use detection_activity to get the number of syllables from all imitations\n",
    "sr = 44100\n",
    "\n",
    "for j in range(int(num_row/100)):\n",
    "    \n",
    "    each_number_events = []\n",
    "\n",
    "    for i in tqdm(range(100)):\n",
    "\n",
    "        # Use this part for imitations\n",
    "        temp_sub = audio[100*j+i,0]\n",
    "        temp_spe = audio[100*j+i,1]\n",
    "        rdata = audio[100*j+i,2:-1]\n",
    "        rdata_nz = np.nonzero(rdata)[0][-1]\n",
    "        fdata = rdata[0:rdata_nz]\n",
    " \n",
    "        if np.mean(lb.feature.spectral_flatness(fdata)) > 0.35:\n",
    "            number_events.append(0)\n",
    "    \n",
    "        else:\n",
    "            start, end = detect_activity(fdata,sr)\n",
    "            activity_count = len(start)\n",
    "            each_number_events.append(activity_count)\n",
    "    \n",
    "    # counting the number of subject\n",
    "    total_subject += 1        \n",
    " \n",
    "    each_number_events = np.array(each_number_events)\n",
    "    all_number_events = np.vstack((all_number_events, each_number_events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(each_number_events))\n",
    "print(total_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the ratio between the number of syllables in stimuli and imitations for each subject\n",
    "for i in range(1,total_subject+1):\n",
    "    if i == 1:\n",
    "        data_ratio = np.round(np.array(all_number_events[i,:] / all_number_events[0,:]),decimals=1)\n",
    "        print(np.shape(data_ratio))\n",
    "    else:\n",
    "        data_ratio = np.vstack((data_ratio,np.round(np.array(all_number_events[i,:] / all_number_events[0,:]),decimals = 1)))\n",
    "        print(np.shape(data_ratio))        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize the species-wise ratio\n",
    "for species in range(10):\n",
    "    for i in range (total_subject):\n",
    "        if i == 0:\n",
    "            temp_data = data_ratio[i,species*10 : (species+1)*10-1]\n",
    "        else:\n",
    "            temp_data = np.hstack((temp_data,data_ratio[i,species*10 : (species+1)*10-1]))\n",
    "            \n",
    "    if species == 0:\n",
    "        species_data = temp_data\n",
    "    else:\n",
    "        species_data = np.vstack((species_data,temp_data))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density plot for each subject\n",
    "from scipy.stats import gaussian_kde\n",
    "for i in range(total_subject):\n",
    "    if i == 0:\n",
    "        density = gaussian_kde(data_ratio[i,:])\n",
    "        xs = np.linspace(0,4,100)\n",
    "        density.covariance_factor = lambda : .25\n",
    "        density._compute_covariance()\n",
    "        plt.plot(xs,density(xs))\n",
    "    else:\n",
    "        density = gaussian_kde(data_ratio[i,:])\n",
    "        density.covariance_factor = lambda : .25\n",
    "        density._compute_covariance()\n",
    "        plt.plot(xs,density(xs))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density plot for each species\n",
    "for i in range(10):\n",
    "    if i == 0:\n",
    "        species_density = gaussian_kde(species_data[i,:])\n",
    "        xs = np.linspace(0,4,100)\n",
    "        species_density.covariance_factor = lambda : .25\n",
    "        species_density._compute_covariance()\n",
    "        plt.plot(xs,species_density(xs))\n",
    "    else:\n",
    "        species_density = gaussian_kde(species_data[i,:])\n",
    "        species_density.covariance_factor = lambda : .25\n",
    "        species_density._compute_covariance()\n",
    "        plt.plot(xs,species_density(xs))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
